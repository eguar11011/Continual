{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a858368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e2071a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.backbone.conv1.weight                (64, 3, 7, 7)\n",
      "model.backbone.bn1.weight                  (64,)\n",
      "model.backbone.bn1.bias                    (64,)\n",
      "model.backbone.bn1.running_mean            (64,)\n",
      "model.backbone.bn1.running_var             (64,)\n",
      "model.backbone.bn1.num_batches_tracked     ()\n",
      "model.backbone.layer1.0.conv1.weight       (64, 64, 3, 3)\n",
      "model.backbone.layer1.0.bn1.weight         (64,)\n",
      "model.backbone.layer1.0.bn1.bias           (64,)\n",
      "model.backbone.layer1.0.bn1.running_mean   (64,)\n",
      "model.backbone.layer1.0.bn1.running_var    (64,)\n",
      "model.backbone.layer1.0.bn1.num_batches_tracked   ()\n",
      "model.backbone.layer1.0.conv2.weight       (64, 64, 3, 3)\n",
      "model.backbone.layer1.0.bn2.weight         (64,)\n",
      "model.backbone.layer1.0.bn2.bias           (64,)\n",
      "model.backbone.layer1.0.bn2.running_mean   (64,)\n",
      "model.backbone.layer1.0.bn2.running_var    (64,)\n",
      "model.backbone.layer1.0.bn2.num_batches_tracked   ()\n",
      "model.backbone.layer1.1.conv1.weight       (64, 64, 3, 3)\n",
      "model.backbone.layer1.1.bn1.weight         (64,)\n",
      "model.backbone.layer1.1.bn1.bias           (64,)\n",
      "model.backbone.layer1.1.bn1.running_mean   (64,)\n",
      "model.backbone.layer1.1.bn1.running_var    (64,)\n",
      "model.backbone.layer1.1.bn1.num_batches_tracked   ()\n",
      "model.backbone.layer1.1.conv2.weight       (64, 64, 3, 3)\n",
      "model.backbone.layer1.1.bn2.weight         (64,)\n",
      "model.backbone.layer1.1.bn2.bias           (64,)\n",
      "model.backbone.layer1.1.bn2.running_mean   (64,)\n",
      "model.backbone.layer1.1.bn2.running_var    (64,)\n",
      "model.backbone.layer1.1.bn2.num_batches_tracked   ()\n",
      "model.backbone.layer2.0.conv1.weight       (128, 64, 3, 3)\n",
      "model.backbone.layer2.0.bn1.weight         (128,)\n",
      "model.backbone.layer2.0.bn1.bias           (128,)\n",
      "model.backbone.layer2.0.bn1.running_mean   (128,)\n",
      "model.backbone.layer2.0.bn1.running_var    (128,)\n",
      "model.backbone.layer2.0.bn1.num_batches_tracked   ()\n",
      "model.backbone.layer2.0.conv2.weight       (128, 128, 3, 3)\n",
      "model.backbone.layer2.0.bn2.weight         (128,)\n",
      "model.backbone.layer2.0.bn2.bias           (128,)\n",
      "model.backbone.layer2.0.bn2.running_mean   (128,)\n",
      "model.backbone.layer2.0.bn2.running_var    (128,)\n",
      "model.backbone.layer2.0.bn2.num_batches_tracked   ()\n",
      "model.backbone.layer2.0.downsample.0.weight   (128, 64, 1, 1)\n",
      "model.backbone.layer2.0.downsample.1.weight   (128,)\n",
      "model.backbone.layer2.0.downsample.1.bias   (128,)\n",
      "model.backbone.layer2.0.downsample.1.running_mean   (128,)\n",
      "model.backbone.layer2.0.downsample.1.running_var   (128,)\n",
      "model.backbone.layer2.0.downsample.1.num_batches_tracked   ()\n",
      "model.backbone.layer2.1.conv1.weight       (128, 128, 3, 3)\n",
      "model.backbone.layer2.1.bn1.weight         (128,)\n",
      "model.backbone.layer2.1.bn1.bias           (128,)\n",
      "model.backbone.layer2.1.bn1.running_mean   (128,)\n",
      "model.backbone.layer2.1.bn1.running_var    (128,)\n",
      "model.backbone.layer2.1.bn1.num_batches_tracked   ()\n",
      "model.backbone.layer2.1.conv2.weight       (128, 128, 3, 3)\n",
      "model.backbone.layer2.1.bn2.weight         (128,)\n",
      "model.backbone.layer2.1.bn2.bias           (128,)\n",
      "model.backbone.layer2.1.bn2.running_mean   (128,)\n",
      "model.backbone.layer2.1.bn2.running_var    (128,)\n",
      "model.backbone.layer2.1.bn2.num_batches_tracked   ()\n",
      "model.backbone.layer3.0.conv1.weight       (256, 128, 3, 3)\n",
      "model.backbone.layer3.0.bn1.weight         (256,)\n",
      "model.backbone.layer3.0.bn1.bias           (256,)\n",
      "model.backbone.layer3.0.bn1.running_mean   (256,)\n",
      "model.backbone.layer3.0.bn1.running_var    (256,)\n",
      "model.backbone.layer3.0.bn1.num_batches_tracked   ()\n",
      "model.backbone.layer3.0.conv2.weight       (256, 256, 3, 3)\n",
      "model.backbone.layer3.0.bn2.weight         (256,)\n",
      "model.backbone.layer3.0.bn2.bias           (256,)\n",
      "model.backbone.layer3.0.bn2.running_mean   (256,)\n",
      "model.backbone.layer3.0.bn2.running_var    (256,)\n",
      "model.backbone.layer3.0.bn2.num_batches_tracked   ()\n",
      "model.backbone.layer3.0.downsample.0.weight   (256, 128, 1, 1)\n",
      "model.backbone.layer3.0.downsample.1.weight   (256,)\n",
      "model.backbone.layer3.0.downsample.1.bias   (256,)\n",
      "model.backbone.layer3.0.downsample.1.running_mean   (256,)\n",
      "model.backbone.layer3.0.downsample.1.running_var   (256,)\n",
      "model.backbone.layer3.0.downsample.1.num_batches_tracked   ()\n",
      "model.backbone.layer3.1.conv1.weight       (256, 256, 3, 3)\n",
      "model.backbone.layer3.1.bn1.weight         (256,)\n",
      "model.backbone.layer3.1.bn1.bias           (256,)\n",
      "model.backbone.layer3.1.bn1.running_mean   (256,)\n",
      "model.backbone.layer3.1.bn1.running_var    (256,)\n",
      "model.backbone.layer3.1.bn1.num_batches_tracked   ()\n",
      "model.backbone.layer3.1.conv2.weight       (256, 256, 3, 3)\n",
      "model.backbone.layer3.1.bn2.weight         (256,)\n",
      "model.backbone.layer3.1.bn2.bias           (256,)\n",
      "model.backbone.layer3.1.bn2.running_mean   (256,)\n",
      "model.backbone.layer3.1.bn2.running_var    (256,)\n",
      "model.backbone.layer3.1.bn2.num_batches_tracked   ()\n",
      "model.backbone.layer4.0.conv1.weight       (512, 256, 3, 3)\n",
      "model.backbone.layer4.0.bn1.weight         (512,)\n",
      "model.backbone.layer4.0.bn1.bias           (512,)\n",
      "model.backbone.layer4.0.bn1.running_mean   (512,)\n",
      "model.backbone.layer4.0.bn1.running_var    (512,)\n",
      "model.backbone.layer4.0.bn1.num_batches_tracked   ()\n",
      "model.backbone.layer4.0.conv2.weight       (512, 512, 3, 3)\n",
      "model.backbone.layer4.0.bn2.weight         (512,)\n",
      "model.backbone.layer4.0.bn2.bias           (512,)\n",
      "model.backbone.layer4.0.bn2.running_mean   (512,)\n",
      "model.backbone.layer4.0.bn2.running_var    (512,)\n",
      "model.backbone.layer4.0.bn2.num_batches_tracked   ()\n",
      "model.backbone.layer4.0.downsample.0.weight   (512, 256, 1, 1)\n",
      "model.backbone.layer4.0.downsample.1.weight   (512,)\n",
      "model.backbone.layer4.0.downsample.1.bias   (512,)\n",
      "model.backbone.layer4.0.downsample.1.running_mean   (512,)\n",
      "model.backbone.layer4.0.downsample.1.running_var   (512,)\n",
      "model.backbone.layer4.0.downsample.1.num_batches_tracked   ()\n",
      "model.backbone.layer4.1.conv1.weight       (512, 512, 3, 3)\n",
      "model.backbone.layer4.1.bn1.weight         (512,)\n",
      "model.backbone.layer4.1.bn1.bias           (512,)\n",
      "model.backbone.layer4.1.bn1.running_mean   (512,)\n",
      "model.backbone.layer4.1.bn1.running_var    (512,)\n",
      "model.backbone.layer4.1.bn1.num_batches_tracked   ()\n",
      "model.backbone.layer4.1.conv2.weight       (512, 512, 3, 3)\n",
      "model.backbone.layer4.1.bn2.weight         (512,)\n",
      "model.backbone.layer4.1.bn2.bias           (512,)\n",
      "model.backbone.layer4.1.bn2.running_mean   (512,)\n",
      "model.backbone.layer4.1.bn2.running_var    (512,)\n",
      "model.backbone.layer4.1.bn2.num_batches_tracked   ()\n",
      "model.head.weight                          (5, 512)\n",
      "model.head.bias                            (5,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ckpt = torch.load(\"ckpt_t0.pt\", map_location=\"cpu\")\n",
    "for k, v in ckpt[\"state_dict\"].items():          # o ckpt.keys() si guardaste solo dict\n",
    "    print(f\"{k:40s}   {tuple(v.shape)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1008a559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logits (sin softmax) ===\n",
      "tensor([[ 14.9622,  -1.0243, -14.4369,   8.1287, -42.2056],\n",
      "        [ 16.9558,  21.6087, -18.2771, -15.4169, -40.5104],\n",
      "        [ -0.5901,  19.4824,  -7.8706, -10.4091, -26.1498]])\n",
      "\n",
      "=== Formas de las activaciones ===\n",
      "conv1   → (3, 64, 112, 112)\n",
      "layer1  → (3, 64, 56, 56)\n",
      "layer2  → (3, 128, 28, 28)\n",
      "layer3  → (3, 256, 14, 14)\n",
      "layer4  → (3, 512, 7, 7)\n",
      "avgpool → (3, 512, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# inspect_activations.py  –  traza las activaciones de tu ResNet-18 (CPU)\n",
    "\n",
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "from collections import OrderedDict\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# ───────────────────────────── 1. Construir la arquitectura ─────────────────────────────\n",
    "def build_model(num_classes: int = 5):\n",
    "    net = resnet18(weights=None)\n",
    "    net.fc = torch.nn.Linear(512, num_classes)   # cabeza personalizada\n",
    "    return net\n",
    "\n",
    "net = build_model().eval().cpu()\n",
    "\n",
    "# ─────────────────────────── 2. Cargar y limpiar el checkpoint ──────────────────────────\n",
    "ckpt = torch.load(\"ckpt_t0.pt\", map_location=\"cpu\")\n",
    "state_dict = ckpt[\"state_dict\"] if \"state_dict\" in ckpt else ckpt\n",
    "\n",
    "fixed = {}\n",
    "for k, v in state_dict.items():\n",
    "    # 1) quita \"model.backbone.\"  •  2) quita \"model.\" o \"backbone.\" si quedan\n",
    "    for prefix in (\"model.backbone.\", \"model.\", \"backbone.\"):\n",
    "        if k.startswith(prefix):\n",
    "            k = k[len(prefix):]\n",
    "            break\n",
    "    # 3) adapta la cabeza: head.*  →  fc.*\n",
    "    if k.startswith(\"head.\"):\n",
    "        k = \"fc.\" + k[len(\"head.\"):]\n",
    "    fixed[k] = v\n",
    "\n",
    "missing, unexpected = net.load_state_dict(fixed, strict=True)\n",
    "assert not missing and not unexpected, f\"faltan {missing} · sobran {unexpected}\"\n",
    "\n",
    "# ───────────────────────────── 3. Hooks para activaciones ───────────────────────────────\n",
    "activations = OrderedDict()\n",
    "def save(tag):\n",
    "    def _hook(_, __, out):\n",
    "        activations[tag] = out.detach().cpu()\n",
    "    return _hook\n",
    "\n",
    "net.conv1.register_forward_hook(save(\"conv1\"))\n",
    "net.layer1.register_forward_hook(save(\"layer1\"))\n",
    "net.layer2.register_forward_hook(save(\"layer2\"))\n",
    "net.layer3.register_forward_hook(save(\"layer3\"))\n",
    "net.layer4.register_forward_hook(save(\"layer4\"))\n",
    "net.avgpool.register_forward_hook(save(\"avgpool\"))\n",
    "\n",
    "# ─────────────────────────── 4. Tres imágenes de CIFAR-10 ──────────────────────────────\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225)),\n",
    "])\n",
    "cifar_test = torchvision.datasets.CIFAR10(\"~/data\", train=False,\n",
    "                                          download=True, transform=transform)\n",
    "batch = torch.stack([cifar_test[i][0] for i in range(3)])   # [3,3,224,224]\n",
    "\n",
    "# ───────────────────────────────── 5. Forward pass ──────────────────────────────────────\n",
    "with torch.no_grad():\n",
    "    logits = net(batch)        # [3, 5]\n",
    "\n",
    "# ─────────────────────────────── 6. Resultados ─────────────────────────────────────────\n",
    "print(\"\\n=== Logits (sin softmax) ===\")\n",
    "print(logits)\n",
    "\n",
    "print(\"\\n=== Formas de las activaciones ===\")\n",
    "for name, act in activations.items():\n",
    "    print(f\"{name:<7} → {tuple(act.shape)}\")\n",
    "    #print(f\"{name:<7} → {tuple(act)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0952bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
